{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations opencv-python-headless\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdvWX3GdyO6q",
        "outputId": "7ffb7c56-664c-410f-f952-daf87cea6058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations\n",
            "  Downloading albumentations-2.0.8-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.15.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.11.7)\n",
            "Collecting albucore==0.0.24 (from albumentations)\n",
            "  Downloading albucore-0.0.24-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting stringzilla>=3.10.4 (from albucore==0.0.24->albumentations)\n",
            "  Downloading stringzilla-3.12.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simsimd>=5.9.2 (from albucore==0.0.24->albumentations)\n",
            "  Downloading simsimd-6.4.9-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n",
            "Downloading albumentations-2.0.8-py3-none-any.whl (369 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m369.4/369.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albucore-0.0.24-py3-none-any.whl (15 kB)\n",
            "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading simsimd-6.4.9-cp311-cp311-manylinux_2_28_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stringzilla-3.12.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.8/307.8 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stringzilla, simsimd, opencv-python-headless, albucore, albumentations\n",
            "Successfully installed albucore-0.0.24 albumentations-2.0.8 opencv-python-headless-4.11.0.86 simsimd-6.4.9 stringzilla-3.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import uuid\n",
        "import hashlib\n",
        "from glob import glob\n",
        "import albumentations as A\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "OMciCwOYyR8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "BASE_DIR = '/content/drive/MyDrive/stain'\n",
        "NORMAL_DIR = os.path.join(BASE_DIR, 'normal')\n",
        "# DEFECT_DIR = os.path.join(BASE_DIR, 'defect')\n",
        "# NORMAL_DIR = os.path.join(BASE_DIR, 'contaminated')\n",
        "# DEFECT_DIR = os.path.join(BASE_DIR, 'line')\n",
        "# NORMAL1_DIR = os.path.join(BASE_DIR, 'string')\n",
        "# DEFECT1_DIR = os.path.join(BASE_DIR, 'flecked')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDSY70xhyUR2",
        "outputId": "2c918d96-4e6f-4829-d4da-ddbd1679c505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
        "    A.GaussianBlur(blur_limit=3, p=0.3),\n",
        "    A.ElasticTransform(p=0.2),\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.05, scale_limit=0.08, rotate_limit=15,\n",
        "        border_mode=cv2.BORDER_REFLECT_101, p=0.5\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z06FR2hFyV9q",
        "outputId": "ebdb691b-f00e-4af4-bd58-c7ede768e102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def image_hash(img):\n",
        "    \"\"\"Compute a hash for an image array to detect duplicates.\"\"\"\n",
        "    return hashlib.md5(img.tobytes()).hexdigest()\n"
      ],
      "metadata": {
        "id": "ExCQk2UAyfm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def augment_folder(src_dir, tgt_dir, target_total):\n",
        "#     os.makedirs(tgt_dir, exist_ok=True)\n",
        "#     # Load existing images and their hashes\n",
        "#     existing_paths = glob(os.path.join(tgt_dir, '*'))\n",
        "#     hashes = set()\n",
        "#     for p in existing_paths:\n",
        "#         img = cv2.imread(p)\n",
        "#         if img is not None:\n",
        "#             hashes.add(image_hash(img))\n",
        "\n",
        "#     current_count = len(existing_paths)\n",
        "#     needed = target_total - current_count\n",
        "#     print(f\"{os.path.basename(src_dir)}: {current_count} existing, need {needed} more\")\n",
        "\n",
        "#     src_paths = glob(os.path.join(src_dir, '*'))\n",
        "#     i = 0\n",
        "#     while needed > 0:\n",
        "#         # cycle through source images\n",
        "#         src_img_path = src_paths[i % len(src_paths)]\n",
        "#         img = cv2.imread(src_img_path)\n",
        "#         if img is None:\n",
        "#             i += 1\n",
        "#             continue\n",
        "\n",
        "#         transformed = augmentation(image=img)['image']\n",
        "#         h = image_hash(transformed)\n",
        "#         if h in hashes:\n",
        "#             # skip duplicates\n",
        "#             i += 1\n",
        "#             continue\n",
        "\n",
        "#         # save uniquely\n",
        "#         out_name = f\"{uuid.uuid4().hex}.png\"\n",
        "#         cv2.imwrite(os.path.join(tgt_dir, out_name), transformed)\n",
        "#         hashes.add(h)\n",
        "#         needed -= 1\n",
        "#         i += 1\n",
        "\n",
        "#     print(f\"Finished augmenting {os.path.basename(src_dir)}; now {target_total} images.\")\n",
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import uuid\n",
        "from glob import glob\n",
        "\n",
        "def augment_folder(src_dir, tgt_dir, target_total):\n",
        "    os.makedirs(tgt_dir, exist_ok=True)\n",
        "\n",
        "    # Load existing images and their hashes\n",
        "    existing_paths = glob(os.path.join(tgt_dir, '*'))\n",
        "    hashes = set()\n",
        "    for p in existing_paths:\n",
        "        img = cv2.imread(p)\n",
        "        if img is not None:\n",
        "            hashes.add(image_hash(img))\n",
        "\n",
        "    current_count = len(existing_paths)\n",
        "    needed = target_total - current_count\n",
        "    print(f\"{os.path.basename(src_dir)}: {current_count} existing, need {needed} more\")\n",
        "\n",
        "    src_paths = glob(os.path.join(src_dir, '*'))\n",
        "    i = 0\n",
        "    duplicate_count = 0  # Track how many duplicates were skipped\n",
        "\n",
        "    while needed > 0:\n",
        "        # cycle through source images\n",
        "        src_img_path = src_paths[i % len(src_paths)]\n",
        "        img = cv2.imread(src_img_path)\n",
        "        if img is None:\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        transformed = augmentation(image=img)['image']\n",
        "        h = image_hash(transformed)\n",
        "        if h in hashes:\n",
        "            duplicate_count += 1  # Count duplicates\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        # save uniquely\n",
        "        out_name = f\"{uuid.uuid4().hex}.png\"\n",
        "        cv2.imwrite(os.path.join(tgt_dir, out_name), transformed)\n",
        "        hashes.add(h)\n",
        "        needed -= 1\n",
        "        i += 1\n",
        "\n",
        "    print(f\"Finished augmenting {os.path.basename(src_dir)}; now {target_total} images.\")\n",
        "    print(f\"Skipped {duplicate_count} duplicate augmented images.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "m3Mv41t4yhmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Normal: from 320 → 500 (80 more)\n",
        "augment_folder(NORMAL_DIR, NORMAL_DIR, target_total=398)\n",
        "\n",
        "# # Defect: from 32 → 500 (320 more)\n",
        "# augment_folder(DEFECT_DIR, DEFECT_DIR, target_total=500)\n",
        "\n",
        "# # # Normal: from 320 → 500 (80 more)\n",
        "# augment_folder(NORMAL_DIR, NORMAL_DIR, target_total=125)\n",
        "\n",
        "# # Defect: from 32 → 500 (320 more)\n",
        "# augment_folder(DEFECT_DIR, DEFECT_DIR, target_total=125)\n",
        "# # # Normal: from 320 → 500 (80 more)\n",
        "# augment_folder(NORMAL_DIR, NORMAL1_DIR, target_total=125)\n",
        "\n",
        "# # Defect: from 32 → 500 (320 more)\n",
        "# augment_folder(DEFECT_DIR, DEFECT1_DIR, target_total=125)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A8wn6EXykg8",
        "outputId": "3a00d4a7-73bd-4481-c104-b574bbe3ca62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normal: 68 existing, need 330 more\n",
            "Finished augmenting normal; now 398 images.\n",
            "Skipped 24 duplicate augmented images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HhfItLT4yn4U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}